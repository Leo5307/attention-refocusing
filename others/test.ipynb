{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "from diffusers.utils import pt_to_pil\n",
    "import torch\n",
    "\n",
    "# stage 1\n",
    "stage_1 = DiffusionPipeline.from_pretrained(\"DeepFloyd/IF-I-XL-v1.0\", variant=\"fp16\", torch_dtype=torch.float16)\n",
    "stage_1.enable_xformers_memory_efficient_attention()  # remove line if torch.__version__ >= 2.0.0\n",
    "stage_1.enable_model_cpu_offload()\n",
    "\n",
    "# stage 2\n",
    "stage_2 = DiffusionPipeline.from_pretrained(\n",
    "    \"DeepFloyd/IF-II-L-v1.0\", text_encoder=None, variant=\"fp16\", torch_dtype=torch.float16\n",
    ")\n",
    "stage_2.enable_xformers_memory_efficient_attention()  # remove line if torch.__version__ >= 2.0.0\n",
    "stage_2.enable_model_cpu_offload()\n",
    "\n",
    "# stage 3\n",
    "safety_modules = {\"feature_extractor\": stage_1.feature_extractor, \"safety_checker\": stage_1.safety_checker, \"watermarker\": stage_1.watermarker}\n",
    "stage_3 = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-x4-upscaler\", **safety_modules, torch_dtype=torch.float16)\n",
    "stage_3.enable_xformers_memory_efficient_attention()  # remove line if torch.__version__ >= 2.0.0\n",
    "stage_3.enable_model_cpu_offload()\n",
    "\n",
    "prompt = 'a photo of a kangaroo wearing an orange hoodie and blue sunglasses standing in front of the eiffel tower holding a sign that says \"very deep learning\"'\n",
    "\n",
    "# text embeds\n",
    "prompt_embeds, negative_embeds = stage_1.encode_prompt(prompt)\n",
    "\n",
    "generator = torch.manual_seed(0)\n",
    "\n",
    "# stage 1\n",
    "image = stage_1(prompt_embeds=prompt_embeds, negative_prompt_embeds=negative_embeds, generator=generator, output_type=\"pt\").images\n",
    "pt_to_pil(image)[0].save(\"./if_stage_I.png\")\n",
    "\n",
    "# stage 2\n",
    "image = stage_2(\n",
    "    image=image, prompt_embeds=prompt_embeds, negative_prompt_embeds=negative_embeds, generator=generator, output_type=\"pt\"\n",
    ").images\n",
    "pt_to_pil(image)[0].save(\"./if_stage_II.png\")\n",
    "\n",
    "# stage 3\n",
    "image = stage_3(prompt=prompt, image=image, generator=generator, noise_level=100).images\n",
    "image[0].save(\"./if_stage_III.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
